---
path: "/weekly-journals/week-2-learner-and-context"
date: "2017-09-12"
title: "Weekly Journal 2: Ch 5 Learner and context. Articles: Peter Hornsby and David Jonassen"
---

## Summary

Task analysis lays the groundwork for good instruction. It helps connect the designer to the learner. May as well call it “empathy synthesis.” Without empathy, the instruction feels contrived and inauthentic. 

It starts with understanding people and contexts. Designers use practical methods to analyze tasks the learners do. They decide what type of analysis to administer. Hierarchical task analysis is one type of task analysis used in UX design. It is also applied to formal instructional tasks.


### Analyzing Learners and Contexts

Instructional Design is about the learner, the environment and their context. Designers should spend time learning about the intended audience and what they do. Without understanding people, an instructional designer can't deliver meaningful instruction and training.

For this, an instructional designer must do the following:
1. **Identify the Population**: The general characteristics a group of potential learners may share. Among many aspects, a particular interest in what is the experience and motivation of these learners is vital to understand. It’s the **who**.
2. **Articulate the Learner’s Environment**: Where the learners spend their time. We need to understand physical and social aspects of their environment. It’s about relevance, the **why**.
3. **Describe the Learning Context**: This reviews resources, constraints, compatibility of learning and feasibility of implementation. It’s the **what**.

### Identify the Population

Before analyzing learners and context, have a target population or audience in mind. The target audience informs you about the people you intend to instruct. Age, grade level, job experience or position is a starting point to learn about the learner.

You can’t stop there, though. A designer must dive deeper and be more specific about what a target audience needs. It’s impossible to know the population at large. Using sampling methods and tryout learners, designers can match the population and their needs.

About the population, a designer should know:
* Entry skills & previous experience or knowledge
* Attitudes
* Motivation
* Education or ability levels
* Learning preferences

### Articulate the Learner’s Environment

For designers, it’s important to know the environment the learners will be using new skills. Designers are authentic and enhance the learner's motivation and relevance in doing so. For instance, if monetary bonus is based on learning a skill, that's motivation. It's their livelihood! A designer needs to know what is at stake to make an impact.

About the environment, a designer should know:
* Managerial Support
* Physical aspects
* Social aspects
* Workplace Skill relevance

### Describe the Learning Context

Lastly, the designer needs to know what is available to learner to make the most of instruction. This includes the **setting** in which instruction takes place and **collateral**, like software or hardware the makes the job possible. Ideally, the location of training and means of delivering it is based upon previous goal analysis.

For learning context, designers should know:
* Compatibility of learning and site
* Availability to simulate workplace
* Adaptability for delivery
* Constraints for learning onsite

The closer a designer can simulate the desired performance, they can expect learners will find more meaning and are able to transfer the new skills.

### Task Analysis Methods for Instructional Design

David Jonassen argues task analysis is essential for good instructional design, but is probably the least understood component of instructional design process. 

Task analysis provides the intellectual basis for instruction, the vehicle for designers to connect the problem or gap in training to the preferred learning outcome. If a designer cannot articulate the problem or outcomes, they will have unsatisfactory instruction.

The design process is ambiguous. Instructional design is no different. Designers can dissolve ambiguity by using critical thinking and reasoning towards solutions. The instructional design process is in fact a problem-solving process, not a procedure in a vacuum.

Why is task analysis the least understood piece of instructional design? Reasons include:

* Designers lack of context
* Inability to disassociate task analysis from needs assessment
* Skipped for other favorable steps like actual development of collateral

Jonassen offers five steps to successful, general task analysis:
1. Identify the training tasks for analysis
2. Evaluate training tasks for feasibility
3. Decompose the training tasks (i.e. scope and sequence)
4. Sequence the task that facilitates learning
5. Classify learning outcomes

To approach task analysis, Jonassen suggests identifying:
* The kind of instruction design
* Task analysis function (sequencing, describing)
* The scope of the design
* The learner's context
* Resources available.

Task analysis may be the most misunderstood or misapplied component of instructional design, yet vital. Using this framework, it is possible to implement. It is a designers business to learn and think about a learners needs and outcomes.

### Hierarchical Task Analysis

Peter Hornsby portrays Hierarchical Task Analysis (HTA) as an analytical and descriptive approach to user experience (UX). HTA helps UX designers understand:
* **What** a system does
* **How** its capabilities translate into a system’s user experience

In short, HTA provides a scaffold of the tasks users need to achieve certain goals. The idea is that a UX designer should break down the task into smaller steps, called subtasks. Subtasks should highlight the major levels in the process of performing a task.

To break down a user’s task:
* Identify a user’s primary goal
* Detail the steps a user performs to achieve their goal
* Optimizing these procedures

While HTA may not describe every single interaction, it does give UX designers a clear understanding of high-level steps. It can be broken down further if necessary and depending on the task.

Hierarchical Task Analysis has many benefits:
* Objectively compare different approaches to the same task
* Capture design rationale
* Understand how a system works at whatever level of abstraction
* It scales with reuse

Lastly, what HTA attractive to UX designers is it’s compatibility to other UX tools like **personas** and **user journeys**. One can and should design task analyses for different personas as to account for the user’s experience with a system.

Hierarchical task analysis is a simple, but effective technique that gives the practitioner a high-level of the user task and experience.

## Critique

### Task Analysis Application

Task analysis seems effective for training and instruction that supports specific tasks or performance of basic job functions. However, it seems less applicable to complex concepts that may not be easily observed or understood. As technology has advanced, knowledge or thought work has introduced new challenges for instructional design. 

Knowledge work, or work conducted by individuals whose main capital is knowledge, relies less on an observable set of skills and explicit tasks and more on intellectual effort and processes that are not easily observable. Engineers, physicians, researchers, and other advanced professionals, who happen to comprise the target audience of a lot of my work, are difficult to engage and train using traditional methods. 

Approaching new concepts with this cohort focuses less on explicit sets of tasks that produce outcomes and more focus on the WIIFM (Why do I care: What’s in it for me?). This involves training that focuses on why something is relevant or important and how it might meet and individuals intrinsic or extrinsic needs. For example, health care reimbursement for physicians and hospitals (i.e. how they get paid by the government) has changed dramatically in the past seven years. It requires learning and understanding new rules, regulations, performance metrics, and restructuring of long entrenched individual and group practices and departments. 

Learning these concepts may not require individual behavior change and the context where they occur varies infinitely. Rather it requires understanding “why” restructuring and practice changes are happening. How they are implemented is largely at the discretion of the individual physician, group and hospital system impacted.   

### Task Analysis and the Cognitive Method

After reading the text, we are convinced a task analysis is necessary. It is very easy to create instructional materials that complete miss the mark if the designer does not account for all associated tasks in a given skill or trade, in order to achieve a goal. However, we’d opt for the task analysis over the job analysis because we think the task analysis offers a more accurate depiction of what is required, even when the goal is performance support driven. We feel like job descriptions and job analysis are often too general and lack the fine details that can truly affect the design process, while also stating would should be, but not necessarily stating what is.

As far as which method of task analysis, well, we are on the fence. We conditionally agree with the Hierarchical task analysis model, and think it works well in certain instructional settings. What the hierarchical task model doesn’t do is account for cognition, which is why we can’t ‘totally’ agree with this model. Even while the hierarchical method could be used for something like recipes, it fails to consider things like the learner may have to consider, like:
* “At what altitude is the baking temperature suggested for? 
* “Am I at a higher altitude? 
* “How do I adjust bake time?”
* “Are the tops of the cookies golden brown?”

We prefer the cognitive method because I don’t know that we will ever be able to escape cognition in learning experiences; learners are not simply digesting information and responding. While learners may be able to self-regulate and answer questions themselves, cognition is inevitable, and there may be a chance they get stuck somewhere in the hierarchical model and make an inference, rather than based on perfect understanding of instructional material. 

### Application to UX

The authors viewpoints all agree that task analysis is an essential piece in the instructional design process. Task analysis rests on learners, contexts, and scope. It is the blueprint for the learning outcomes. In general, we also agree that this step is indispensable in the design process. 

We were intrigued by ideas from Hornsby point out that UX does crossover when it comes to learning, which is the essence of UX is (get people from point A to point B with the least amount of steps). The idea that user journeys and personas can be part of the process is valuable. We see this primarily good for software training, but for higher cognition tasks, it may be difficult to point out the nuance.

One thing that wasn’t mentioned extensively is the scalability of task analysis. Can it be used for the same trainings? It’s a question that professionals around me will always ask. What pieces can be reused over and over again.

### Learning Styles

We disagree with Dick and Carey’s outlook on learning styles.  They seem to write them off as mere preferences. We’d argue that they are important to factor into your analysis and that they can provide real value to understanding your target audience. We know at least anecdotally in my experience that people I’ve interacted with have definitely learned better with one mode of instruction over another. We have as well.  If someone takes that into account for their instruction, we feel we're much more likely to learn.

## Self-reflection

One principle that I found exceptionally helpful is the process of re-explaining your analysis findings to the potential audience prior to advancing in development. Do you understand this? Does it make sense? What did I miss? I have conducted many task analyses and can honestly say I have not done this. It’s simple, straightforward, easy to accomplish and would provide much needed insight into potential pitfalls in execution. We are currently in the process of updating a web-based tool designed to capture improvement work conducted by frontline healthcare professionals. Previous iterations included basic task analysis to identify the appropriate steps and streamline inputting information. However, the information people have been inputting into the tool clearly misses the performance mark. Had we walked a cohort through the initial design, we would have learned that several of the questions were unclear or interpretable in a variety of ways. We are now doing this (re-explain and test questions) with a broad base of users to make sure we’re getting consistent quality in responses. Seems simple, yet sadly, consistently overlooked.

Working in a large organization, resources and support vary depending where you are in the company. Moving into the project, it is going to be critical to consider the environment in which skills will be learned, but not only with the tryout learners. When and if the project moves from pilot to full-scope, it may difficult to determine the environment in which skills will be learned for 2000+ people. Additionally, I have already noticed the importance of analyzing learner characteristics. 

Today, I spoke with a clinical nurse coordinator on the nursing unit we will be working with. When I mentioned we wanted to talk about how nurses impact finances, she immediately paused and told me we are going to have to be mindful of how we frame that, because a quite of few nurses have a bad attitude when the organization approaches learning/teaching with a financial mindset, because they think it should be about the patient. So she ensured me we will need to try, as often as possible, to frame finances around benefitting the patients, and not just making the hospital money. So, while I knew some nurses might have felt that way, I now realize how important it will be to take our time on analyzing learner characteristics so that we can make the learning experience positive, and that they will want to learn, and will learn. 

The author, David Jonassen, mentions that if instructional designers do not spend time analyzing tasks, they have no business designing instruction. Consider me guilty. I never considered that instructional design is equivalent of a detective. It’s about finding the problem and addressing it. The valuable lesson I’ve learned thus far is that task analysis and needs assessment are all about solving a problem. It’s the first necessary step to designing and implementing a course or instruction.

In my professional life, we aren’t in the business of teaching and learning, but I care very much about the learning experience for users learning Qualtrics. But I haven’t considered what goes beyond that. Have I:
* Considered how this affects their job?
* Comprehended how Qualtrics creates success for the learner’s customers.
* Analyzed a learner's background and professional life?

Nope. 

But I started this week after reading the assignment. While very much a task analysis neophyte, I already saw great traction with a client I am working with. 

I work with major clients that use Qualtrics (think Walmart, BMW, USAA). They invest into Qualtrics and expect top notch training. One area I found myself spinning my wheels is in the learner analysis. What do they actually know? I successfully navigated a research meeting with a client this week around the roles of their users. In fact, I made the client go back and examine how their users will Qualtrics. They were intrigued by the idea and hadn’t considered it essential.

I meet with them again on Monday. I can’t wait to see they provide.


I’ve never really thought about task analysis before we talked about it in class and did the reading.  I’m currently in the process of designing some instruction for my fellow software engineers at work to help them make software more accessible.  The trouble I think I will have doing task analysis on the problem is how broad it is.  There are so many variables that go into it.  For example, we work with three different screen reader technologies.  Each of those screen readers can behave differently.  We also deal with keyboard only navigation which in an of itself can be complex.  With all these different things I think I’ll need to do multiple task analyses and break down things even farther.





